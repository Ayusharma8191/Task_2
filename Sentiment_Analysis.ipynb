{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "gyQanll_T9Yo"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download necessary resources (run this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ZtqF4hVcyr",
        "outputId": "5554a7c0-d4a2-4878-eea9-4501b780a32a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (Replace 'your_file.csv' with your file path)\n",
        "df = pd.read_csv('/content/sentiment_analysis.csv')\n",
        "\n",
        "# Assuming the columns are 'review' for text and 'sentiment' for labels\n",
        "reviews = df['text']\n",
        "labels = df['sentiment']\n"
      ],
      "metadata": {
        "id": "0Lj19DoqVeqm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenization and Stopword Removal\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text (convert to lowercase and split by spaces)\n",
        "        tokens = text.lower().split()\n",
        "\n",
        "                # Remove stopwords and punctuation\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "\n",
        "        return \" \".join(tokens)\n",
        "\n",
        "                                # Apply preprocessing to all reviews\n",
        "reviews_cleaned = reviews.apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "SiSrg5-tVkWw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews_cleaned.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-A4q6f7VsOO",
        "outputId": "e85f5379-9c51-4d15-844b-8708d8c9b54c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                       great day!!! looks like dream.\n",
            "1                           feel sorry, miss sea beach\n",
            "2                                                angry\n",
            "3    attend class listening teachers reading slide....\n",
            "4                                      want go, let go\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Vectorization using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(reviews_cleaned)\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the model (Using Multinomial Naive Bayes as an example)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Output the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZami8dEV_ur",
        "outputId": "6f49fec8-51bd-457b-9a01-36e5fda494d9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6000\n",
            "Precision: 0.7827\n",
            "Recall: 0.6000\n",
            "F1 Score: 0.5729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ii6umhLuWLJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}